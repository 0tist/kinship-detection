{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'combinations.txt', 'Data Cleaning and Preprocessing (2).ipynb', 'Data Cleaning and Preprocessing reduced.ipynb', 'Data_final.ipynb', 'data_prep.ipynb', 'df_final.csv', 'jayesh model.ipynb', 'kinship-detection-with-vgg16.ipynb', 'One Shot VGG Submission.ipynb', 'one_shot_vgg.ipynb', 'sample_submission.csv', 'test', 'train', 'train_relationships.csv', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necassary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\abhish~1\\appdata\\local\\temp\\pip-req-build-o2ufb4pm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Error [WinError 2] The system cannot find the file specified while executing command git clone -q https://github.com/rcmalli/keras-vggface.git C:\\Users\\ABHISH~1\\AppData\\Local\\Temp\\pip-req-build-o2ufb4pm\n",
      "Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Requirement already satisfied: scipy>=0.14 in d:\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in d:\\anaconda3\\lib\\site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in d:\\anaconda3\\lib\\site-packages (from keras) (1.15.4)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda3\\lib\\site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-79c22ee96404>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalMaxPool2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalAvgPool2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiply\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSubtract\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from random import choice, sample\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"../input/train_relationships.csv\"\n",
    "train_folders_path = \"../input/train/\"\n",
    "val_famillies = \"F09\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(train_folders_path + \"*/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set consists only family 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [x for x in all_images if val_famillies not in x]\n",
    "val_images = [x for x in all_images if val_famillies in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person_to_images_map = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_images:\n",
    "    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "val_person_to_images_map = defaultdict(list)\n",
    "\n",
    "for x in val_images:\n",
    "    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "relationships = pd.read_csv(train_file_path)\n",
    "relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
    "relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]\n",
    "\n",
    "train = [x for x in relationships if val_famillies not in x[0]]\n",
    "val = [x for x in relationships if val_famillies in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
      "94699520/94694792 [==============================] - 8s 0us/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 1, 1, 2048)   0           vggface_resnet50[1][0]           \n",
      "                                                                 vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 1, 1, 2048)   0           vggface_resnet50[1][0]           \n",
      "                                                                 vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1, 1, 100)    204900      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 1, 100)    204900      subtract_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 1, 200)    0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          20100       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 25)           2525        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            26          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,993,603\n",
      "Trainable params: 23,940,483\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def read_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = np.array(img).astype(np.float)\n",
    "    return preprocess_input(img, version=2)\n",
    "\n",
    "\n",
    "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        labels = [1] * len(batch_tuples)\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
    "                batch_tuples.append((p1, p2))\n",
    "                labels.append(0)\n",
    "\n",
    "        for x in batch_tuples:\n",
    "            if not len(person_to_images_map[x[0]]):\n",
    "                print(x[0])\n",
    "\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = np.array([read_img(x) for x in X1])\n",
    "\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = np.array([read_img(x) for x in X2])\n",
    "\n",
    "        yield [X1, X2], labels\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    input_1 = Input(shape=(224, 224, 3))\n",
    "    input_2 = Input(shape=(224, 224, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for layer in base_model.layers[:-3]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "\n",
    "    merged_add = Add()([x1, x2])\n",
    "    merged_sub = Subtract()([x1,x2])\n",
    "    \n",
    "    merged_add = Conv2D(100 , [1,1] )(merged_add)\n",
    "    merged_sub = Conv2D(100 , [1,1] )(merged_sub)\n",
    "    \n",
    "    merged = Concatenate(axis=-1)([merged_add, merged_sub])\n",
    "    \n",
    "    merged = Flatten()(merged)\n",
    "\n",
    "    merged = Dense(100, activation=\"relu\")(merged)\n",
    "    merged = Dropout(0.3)(merged)\n",
    "    merged = Dense(25, activation=\"relu\")(merged)\n",
    "    merged = Dropout(0.3)(merged)\n",
    "    out = Dense(1, activation=\"sigmoid\")(merged)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "file_path = \"vgg_face.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 105s 526ms/step - loss: 1.2316 - acc: 0.5394 - val_loss: 0.7537 - val_acc: 0.5994\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59937, saving model to vgg_face.h5\n",
      "Epoch 2/130\n",
      "200/200 [==============================] - 78s 390ms/step - loss: 0.8789 - acc: 0.5725 - val_loss: 0.7092 - val_acc: 0.6088\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59937 to 0.60875, saving model to vgg_face.h5\n",
      "Epoch 3/130\n",
      "200/200 [==============================] - 78s 391ms/step - loss: 0.7836 - acc: 0.5741 - val_loss: 0.6885 - val_acc: 0.6081\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.60875\n",
      "Epoch 4/130\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.6929 - acc: 0.6081 - val_loss: 0.6612 - val_acc: 0.6044\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.60875\n",
      "Epoch 5/130\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.7112 - acc: 0.5900 - val_loss: 0.6429 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.60875 to 0.62375, saving model to vgg_face.h5\n",
      "Epoch 6/130\n",
      "200/200 [==============================] - 78s 389ms/step - loss: 0.6717 - acc: 0.6138 - val_loss: 0.6252 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.62375\n",
      "Epoch 7/130\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.6386 - acc: 0.6375 - val_loss: 0.6033 - val_acc: 0.6775\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.62375 to 0.67750, saving model to vgg_face.h5\n",
      "Epoch 8/130\n",
      "200/200 [==============================] - 77s 386ms/step - loss: 0.6400 - acc: 0.6450 - val_loss: 0.6043 - val_acc: 0.6594\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.67750\n",
      "Epoch 9/130\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.6384 - acc: 0.6381 - val_loss: 0.5996 - val_acc: 0.6538\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.67750\n",
      "Epoch 10/130\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.6118 - acc: 0.6544 - val_loss: 0.5943 - val_acc: 0.6650\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.67750\n",
      "Epoch 11/130\n",
      "200/200 [==============================] - 79s 393ms/step - loss: 0.6009 - acc: 0.6553 - val_loss: 0.5930 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.67750 to 0.68125, saving model to vgg_face.h5\n",
      "Epoch 12/130\n",
      "200/200 [==============================] - 77s 385ms/step - loss: 0.6009 - acc: 0.6647 - val_loss: 0.6018 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.68125 to 0.69750, saving model to vgg_face.h5\n",
      "Epoch 13/130\n",
      "200/200 [==============================] - 78s 388ms/step - loss: 0.5913 - acc: 0.6831 - val_loss: 0.5845 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69750\n",
      "Epoch 14/130\n",
      "200/200 [==============================] - 78s 390ms/step - loss: 0.5743 - acc: 0.6916 - val_loss: 0.5660 - val_acc: 0.7006\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.69750 to 0.70063, saving model to vgg_face.h5\n",
      "Epoch 15/130\n",
      "200/200 [==============================] - 76s 380ms/step - loss: 0.5746 - acc: 0.6916 - val_loss: 0.5648 - val_acc: 0.7094\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.70063 to 0.70937, saving model to vgg_face.h5\n",
      "Epoch 16/130\n",
      "200/200 [==============================] - 76s 381ms/step - loss: 0.5633 - acc: 0.7006 - val_loss: 0.5835 - val_acc: 0.7031\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.70937\n",
      "Epoch 17/130\n",
      "200/200 [==============================] - 78s 390ms/step - loss: 0.5404 - acc: 0.7253 - val_loss: 0.5594 - val_acc: 0.6994\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.70937\n",
      "Epoch 18/130\n",
      "200/200 [==============================] - 78s 388ms/step - loss: 0.5305 - acc: 0.7247 - val_loss: 0.5452 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.70937 to 0.71875, saving model to vgg_face.h5\n",
      "Epoch 19/130\n",
      "200/200 [==============================] - 75s 374ms/step - loss: 0.5213 - acc: 0.7369 - val_loss: 0.5285 - val_acc: 0.7338\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.71875 to 0.73375, saving model to vgg_face.h5\n",
      "Epoch 20/130\n",
      "200/200 [==============================] - 75s 377ms/step - loss: 0.5266 - acc: 0.7284 - val_loss: 0.5316 - val_acc: 0.7331\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.73375\n",
      "Epoch 21/130\n",
      "200/200 [==============================] - 77s 386ms/step - loss: 0.5409 - acc: 0.7122 - val_loss: 0.5342 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.73375\n",
      "Epoch 22/130\n",
      "200/200 [==============================] - 78s 389ms/step - loss: 0.5183 - acc: 0.7350 - val_loss: 0.5336 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.73375\n",
      "Epoch 23/130\n",
      "200/200 [==============================] - 77s 383ms/step - loss: 0.5325 - acc: 0.7291 - val_loss: 0.5299 - val_acc: 0.7356\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.73375 to 0.73562, saving model to vgg_face.h5\n",
      "Epoch 24/130\n",
      "200/200 [==============================] - 75s 373ms/step - loss: 0.5154 - acc: 0.7363 - val_loss: 0.5380 - val_acc: 0.7406\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.73562 to 0.74062, saving model to vgg_face.h5\n",
      "Epoch 25/130\n",
      "200/200 [==============================] - 75s 376ms/step - loss: 0.4977 - acc: 0.7550 - val_loss: 0.5134 - val_acc: 0.7375\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.74062\n",
      "Epoch 26/130\n",
      "200/200 [==============================] - 77s 387ms/step - loss: 0.5142 - acc: 0.7441 - val_loss: 0.5031 - val_acc: 0.7544\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.74062 to 0.75438, saving model to vgg_face.h5\n",
      "Epoch 27/130\n",
      "200/200 [==============================] - 75s 375ms/step - loss: 0.4879 - acc: 0.7697 - val_loss: 0.5122 - val_acc: 0.7450\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.75438\n",
      "Epoch 28/130\n",
      "200/200 [==============================] - 77s 384ms/step - loss: 0.5014 - acc: 0.7600 - val_loss: 0.5218 - val_acc: 0.7381\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.75438\n",
      "Epoch 29/130\n",
      "200/200 [==============================] - 76s 381ms/step - loss: 0.4836 - acc: 0.7597 - val_loss: 0.5184 - val_acc: 0.7394\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.75438\n",
      "Epoch 30/130\n",
      "  8/200 [>.............................] - ETA: 1:23 - loss: 0.4876 - acc: 0.7344"
     ]
    }
   ],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=130, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [01:22,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"../input/test/\"\n",
    "\n",
    "\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "    X1 = [x.split(\"-\")[0] for x in batch]\n",
    "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "    X2 = [x.split(\"-\")[1] for x in batch]\n",
    "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "    pred = model.predict([X1, X2]).ravel().tolist()\n",
    "    predictions += pred\n",
    "\n",
    "submission['is_related'] = predictions\n",
    "\n",
    "submission.to_csv(\"vgg_face.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
